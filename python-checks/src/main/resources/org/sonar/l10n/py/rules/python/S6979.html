<p>This rule raises when a <code>torch.autograd.Variable</code> is instantiated.</p>
<h2>Why is this an issue?</h2>
<p>The Pytorch Variable API has been deprecated. The behavior of Variables is now provided by the Pytorch tensors and can be controlled with the
<code>requires_grad</code> parameter.</p>
<p>The Variable API now returns tensors anyway, so there should not be any breaking changes.</p>
<h2>How to fix it</h2>
<p>Replace the call to <code>torch.autograd.Variable</code> with a call to <code>torch.tensor</code> and set the <code>requires_grad</code> attribute
to <code>True</code> if needed.</p>
<h3>Code examples</h3>
<h4>Noncompliant code example</h4>
<pre data-diff-id="1" data-diff-type="noncompliant">
import torch

x = torch.autograd.Variable(torch.tensor([1.0]), requires_grad=True) # Noncompliant
x2 = torch.autograd.Variable(torch.tensor([1.0])) # Noncompliant
</pre>
<h4>Compliant solution</h4>
<pre data-diff-id="1" data-diff-type="compliant">
import torch

x = torch.tensor([1.0], requires_grad=True)
x2 = torch.tensor([1.0])
</pre>
<h2>Resources</h2>
<h3>Documentation</h3>
<ul>
  <li> Pytorch documentation - <a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated">Variable API</a> </li>
</ul>

