from .image_list import ImageList as ImageList
from .roi_heads import paste_masks_in_image as paste_masks_in_image
from torch import Tensor as Tensor, nn
from typing import Any, Dict, List, Optional, Tuple

class GeneralizedRCNNTransform(nn.Module):
    min_size: Any
    max_size: Any
    image_mean: Any
    image_std: Any
    size_divisible: Any
    fixed_size: Any
    def __init__(self, min_size: int, max_size: int, image_mean: List[float], image_std: List[float], size_divisible: int = ..., fixed_size: Optional[Tuple[int, int]] = ..., **kwargs: Any) -> None: ...
    def forward(self, images: List[Tensor], targets: Optional[List[Dict[str, Tensor]]] = ...) -> Tuple[ImageList, Optional[List[Dict[str, Tensor]]]]: ...
    def normalize(self, image: Tensor) -> Tensor: ...
    def torch_choice(self, k: List[int]) -> int: ...
    def resize(self, image: Tensor, target: Optional[Dict[str, Tensor]] = ...) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]: ...
    def max_by_axis(self, the_list: List[List[int]]) -> List[int]: ...
    def batch_images(self, images: List[Tensor], size_divisible: int = ...) -> Tensor: ...
    def postprocess(self, result: List[Dict[str, Tensor]], image_shapes: List[Tuple[int, int]], original_image_sizes: List[Tuple[int, int]]) -> List[Dict[str, Tensor]]: ...

def resize_keypoints(keypoints: Tensor, original_size: List[int], new_size: List[int]) -> Tensor: ...
def resize_boxes(boxes: Tensor, original_size: List[int], new_size: List[int]) -> Tensor: ...
