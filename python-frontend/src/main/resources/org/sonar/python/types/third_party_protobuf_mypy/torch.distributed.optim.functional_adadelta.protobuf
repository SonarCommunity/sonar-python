
+torch.distributed.optim.functional_adadeltaÜ
_FunctionalAdadelta?torch.distributed.optim.functional_adadelta._FunctionalAdadelta"builtins.object*∏
__init__Htorch.distributed.optim.functional_adadelta._FunctionalAdadelta.__init__"
None*ç
selfÇ
?torch.distributed.optim.functional_adadelta._FunctionalAdadelta"?torch.distributed.optim.functional_adadelta._FunctionalAdadelta*n
paramsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list**
lr 
builtins.float"builtins.float *+
rho 
builtins.float"builtins.float *+
eps 
builtins.float"builtins.float *4
weight_decay 
builtins.float"builtins.float *-
foreach
builtins.bool"builtins.bool *.
maximize
builtins.bool"builtins.bool *=
_allow_empty_param_list
builtins.bool"builtins.bool *ñ
stepDtorch.distributed.optim.functional_adadelta._FunctionalAdadelta.step"
Any*ç
selfÇ
?torch.distributed.optim.functional_adadelta._FunctionalAdadelta"?torch.distributed.optim.functional_adadelta._FunctionalAdadelta*Æ
	gradientsû
/builtins.list[Union[torch._tensor.Tensor,None]]\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None"builtins.list8r—
defaultsHtorch.distributed.optim.functional_adadelta._FunctionalAdadelta.defaults{
*builtins.dict[builtins.str,builtins.float]
builtins.str"builtins.str 
builtins.float"builtins.float"builtins.dictrr
foreachGtorch.distributed.optim.functional_adadelta._FunctionalAdadelta.foreach
builtins.bool"builtins.boolrt
maximizeHtorch.distributed.optim.functional_adadelta._FunctionalAdadelta.maximize
builtins.bool"builtins.boolrØ
param_groupKtorch.distributed.optim.functional_adadelta._FunctionalAdadelta.param_group“
?builtins.dict[builtins.str,builtins.list[torch._tensor.Tensor]]
builtins.str"builtins.strb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.dictrW
stateEtorch.distributed.optim.functional_adadelta._FunctionalAdadelta.state
Any*ß
__annotations__;torch.distributed.optim.functional_adadelta.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
Ftorch.optim._functional *ä
__all__3torch.distributed.optim.functional_adadelta.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list