
#torch.distributed.fsdp._shard_utilsº(
DShard/torch.distributed._tensor.placement_types.Shard"3torch.distributed._tensor.placement_types.Placement*‡
_split_tensor=torch.distributed._tensor.placement_types.Shard._split_tensor"ú
FTuple[builtins.list[torch._tensor.Tensor],builtins.list[builtins.int]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.listJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*,

num_chunks
builtins.int"builtins.int*2
with_padding
builtins.bool"builtins.bool *0

contiguous
builtins.bool"builtins.bool *’
_local_shard_size_on_dimHtorch.distributed._tensor.placement_types.Shard._local_shard_size_on_dim"`
 Tuple[builtins.int,builtins.int]
builtins.int"builtins.int
builtins.int"builtins.int*-
size_on_dim
builtins.int"builtins.int*,

num_chunks
builtins.int"builtins.int*&
rank
builtins.int"builtins.int*3
return_offset
builtins.bool"builtins.bool 0:staticmethodh*°
_shard_tensor=torch.distributed._tensor.placement_types.Shard._shard_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*ë
_reduce_shard_tensorDtorch.distributed._tensor.placement_types.Shard._reduce_shard_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*+
	reduce_op
builtins.str"builtins.str**
mesh_dim
builtins.int"builtins.int*«
_to_replicate_tensorDtorch.distributed._tensor.placement_types.Shard._to_replicate_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*>
local_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*e
current_logical_shapeJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*ñ
_replicate_to_shardCtorch.distributed._tensor.placement_types.Shard._replicate_to_shard",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*>
local_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*-
shard_index
builtins.int"builtins.int*Ö
_to_new_shard_dimAtorch.distributed._tensor.placement_types.Shard._to_new_shard_dim",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*>
local_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*e
current_logical_shapeJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*/
new_shard_dim
builtins.int"builtins.int*ì
__eq__6torch.distributed._tensor.placement_types.Shard.__eq__"
builtins.bool"builtins.bool*db
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*$"
builtins.object"builtins.object*Ð
__hash__8torch.distributed._tensor.placement_types.Shard.__hash__"
builtins.int"builtins.int*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*È
__repr__8torch.distributed._tensor.placement_types.Shard.__repr__"
builtins.str"builtins.str*db
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*Æ
__str__7torch.distributed._tensor.placement_types.Shard.__str__"
builtins.str"builtins.str*db
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*ã
__init__8torch.distributed._tensor.placement_types.Shard.__init__"
None*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*%
dim
builtins.int"builtins.int8rX
dim3torch.distributed._tensor.placement_types.Shard.dim
builtins.int"builtins.intrö
__dataclass_fields__Dtorch.distributed._tensor.placement_types.Shard.__dataclass_fields__—
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict‰
_get_remote_device_str:torch.distributed.fsdp._shard_utils._get_remote_device_str*
rank*
device_type*
num_devices_per_nodeÙ
_create_chunk_sharded_tensor@torch.distributed.fsdp._shard_utils._create_chunk_sharded_tensor"v
9torch.distributed._shard.sharded_tensor.api.ShardedTensor"9torch.distributed._shard.sharded_tensor.api.ShardedTensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
rank
builtins.int"builtins.int*,

world_size
builtins.int"builtins.int*6
num_devices_per_node
builtins.int"builtins.int*Z
pgR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*[
deviceM
Union[torch._C.device,None]"
torch._C.device"torch._C.device
None ë
_create_chunk_dtensor9torch.distributed.fsdp._shard_utils._create_chunk_dtensor"N
%torch.distributed._tensor.api.DTensor"%torch.distributed._tensor.api.DTensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
rank
builtins.int"builtins.int*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh…
_all_gather_dtensor7torch.distributed.fsdp._shard_utils._all_gather_dtensor",
torch._tensor.Tensor"torch._tensor.Tensor*Z
tensorN
%torch.distributed._tensor.api.DTensor"%torch.distributed._tensor.api.DTensor*ª
parent_mesh˜
4Union[torch.distributed.device_mesh.DeviceMesh,None]T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh
None*Ÿ
__annotations__3torch.distributed.fsdp._shard_utils.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
disttorch.distributed 