
(torch.distributed.optim.functional_rpropù
_FunctionalRprop9torch.distributed.optim.functional_rprop._FunctionalRprop"builtins.object*è
__init__Btorch.distributed.optim.functional_rprop._FunctionalRprop.__init__"
None*Ä
selfv
9torch.distributed.optim.functional_rprop._FunctionalRprop"9torch.distributed.optim.functional_rprop._FunctionalRprop*n
paramsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list**
lr 
builtins.float"builtins.float *x
etasl
$Tuple[builtins.float,builtins.float] 
builtins.float"builtins.float 
builtins.float"builtins.float *~

step_sizesl
$Tuple[builtins.float,builtins.float] 
builtins.float"builtins.float 
builtins.float"builtins.float *-
foreach
builtins.bool"builtins.bool *.
maximize
builtins.bool"builtins.bool *=
_allow_empty_param_list
builtins.bool"builtins.bool *É
step>torch.distributed.optim.functional_rprop._FunctionalRprop.step"
Any*Ä
selfv
9torch.distributed.optim.functional_rprop._FunctionalRprop"9torch.distributed.optim.functional_rprop._FunctionalRprop*Æ
	gradientsû
/builtins.list[Union[torch._tensor.Tensor,None]]\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None"builtins.list8rÀ
defaultsBtorch.distributed.optim.functional_rprop._FunctionalRprop.defaults{
*builtins.dict[builtins.str,builtins.float]
builtins.str"builtins.str 
builtins.float"builtins.float"builtins.dictr¥
etas>torch.distributed.optim.functional_rprop._FunctionalRprop.etasl
$Tuple[builtins.float,builtins.float] 
builtins.float"builtins.float 
builtins.float"builtins.floatr¿

step_sizesDtorch.distributed.optim.functional_rprop._FunctionalRprop.step_sizesl
$Tuple[builtins.float,builtins.float] 
builtins.float"builtins.float 
builtins.float"builtins.floatrl
foreachAtorch.distributed.optim.functional_rprop._FunctionalRprop.foreach
builtins.bool"builtins.boolrn
maximizeBtorch.distributed.optim.functional_rprop._FunctionalRprop.maximize
builtins.bool"builtins.boolr©
param_groupEtorch.distributed.optim.functional_rprop._FunctionalRprop.param_group“
?builtins.dict[builtins.str,builtins.list[torch._tensor.Tensor]]
builtins.str"builtins.strb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.dictrQ
state?torch.distributed.optim.functional_rprop._FunctionalRprop.state
Any*§
__annotations__8torch.distributed.optim.functional_rprop.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
Ftorch.optim._functional *á
__all__0torch.distributed.optim.functional_rprop.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list