
torch.cuda.amp.grad_scalerÿ

GradScaler%torch.cuda.amp.grad_scaler.GradScaler" torch.amp.grad_scaler.GradScaler*§
__init__.torch.cuda.amp.grad_scaler.GradScaler.__init__"
None*X
selfN
%torch.cuda.amp.grad_scaler.GradScaler"%torch.cuda.amp.grad_scaler.GradScaler*2

init_scale 
builtins.float"builtins.float *5
growth_factor 
builtins.float"builtins.float *6
backoff_factor 
builtins.float"builtins.float *3
growth_interval
builtins.int"builtins.int *-
enabled
builtins.bool"builtins.bool 0*–
__annotations__*torch.cuda.amp.grad_scaler.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*y
__all__"torch.cuda.amp.grad_scaler.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list