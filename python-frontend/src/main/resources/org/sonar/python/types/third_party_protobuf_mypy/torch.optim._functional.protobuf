
torch.optim._functional»
sparse_adam#torch.optim._functional.sparse_adam"
Any*n
paramsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*m
gradsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*p
exp_avgsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*s
exp_avg_sqsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*[
state_stepsJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*)
eps 
builtins.float"builtins.float*+
beta1 
builtins.float"builtins.float*+
beta2 
builtins.float"builtins.float*(
lr 
builtins.float"builtins.float*,
maximize
builtins.bool"builtins.bool*“
__annotations__'torch.optim._functional.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict