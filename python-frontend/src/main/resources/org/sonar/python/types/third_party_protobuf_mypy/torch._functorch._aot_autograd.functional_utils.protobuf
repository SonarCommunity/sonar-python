
/torch._functorch._aot_autograd.functional_utilsì
FunctionalTensorMetadataEqJtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq"builtins.object*…
__init__Storch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq.__init__"
None*£
selfò
Jtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq"Jtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*ø
__eq__Qtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq.__eq__"
builtins.bool"builtins.bool*õò
Jtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq"Jtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq*$"
builtins.object"builtins.objectrâ
tensorQtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq.tensor,
torch._tensor.Tensor"torch._tensor.TensorG
to_fun6torch._functorch._aot_autograd.functional_utils.to_fun*
tg
sync_functional_tensorFtorch._functorch._aot_autograd.functional_utils.sync_functional_tensor*
tK
from_fun8torch._functorch._aot_autograd.functional_utils.from_fun*
tG
is_fun6torch._functorch._aot_autograd.functional_utils.is_fun*
t]
has_data_mutationAtorch._functorch._aot_autograd.functional_utils.has_data_mutation*
tá
&are_all_mutations_hidden_from_autogradVtorch._functorch._aot_autograd.functional_utils.are_all_mutations_hidden_from_autograd*
tù
1are_all_mutations_under_no_grad_or_inference_modeatorch._functorch._aot_autograd.functional_utils.are_all_mutations_under_no_grad_or_inference_mode*
ts
was_inductor_storage_resizedLtorch._functorch._aot_autograd.functional_utils.was_inductor_storage_resized*
tŒ
has_metadata_mutationEtorch._functorch._aot_autograd.functional_utils.has_metadata_mutation"
Any*
f_arg
Any*
arg
Any*?
check_only_storage_mutation
builtins.bool"builtins.boolÏ
gen_alias_from_baseCtorch._functorch._aot_autograd.functional_utils.gen_alias_from_base"
Any* 
aliased_base_tensor
Any*
target_meta_tensor
Any*!
target_requires_grad
Any*†
target_functional_tensorˇ
VUnion[torch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq,None]ò
Jtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq"Jtorch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq
None f
has_same_metadataAtorch._functorch._aot_autograd.functional_utils.has_same_metadata*
t1*
t2n
was_tensor_updatedBtorch._functorch._aot_autograd.functional_utils.was_tensor_updated*
arg*
new_argÄ
was_tensor_metadata_updatedKtorch._functorch._aot_autograd.functional_utils.was_tensor_metadata_updated*
arg*
new_arg∏
assert_functional_graphGtorch._functorch._aot_autograd.functional_utils.assert_functional_graph"
builtins.int"builtins.int*6
fx_g,
torch.fx.graph.Graph"torch.fx.graph.Graphæ
$propagate_input_mutation_stacktracesTtorch._functorch._aot_autograd.functional_utils.propagate_input_mutation_stacktraces"
None*6
fx_g,
torch.fx.graph.Graph"torch.fx.graph.GraphÃ
"_check_if_mutation_can_be_in_graphRtorch._functorch._aot_autograd.functional_utils._check_if_mutation_can_be_in_graph"
Any*8
keep_input_mutations
builtins.bool"builtins.bool*
mutates_data
Any*
mutates_metadata
Any*+
mutations_hidden_from_autograd
Any*6
)mutations_under_no_grad_or_inference_mode
Any*%
mutates_storage_metadata
Any*-
 mutation_inductor_storage_resize
Any*
requires_grad
Any*´
__annotations__?torch._functorch._aot_autograd.functional_utils.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*W
aot_joint_log=torch._functorch._aot_autograd.functional_utils.aot_joint_log
Any