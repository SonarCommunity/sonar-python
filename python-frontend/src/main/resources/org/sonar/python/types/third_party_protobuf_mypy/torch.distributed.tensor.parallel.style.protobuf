
'torch.distributed.tensor.parallel.styleù
ParallelStyle5torch.distributed.tensor.parallel.style.ParallelStyle"abc.ABC*À
_apply<torch.distributed.tensor.parallel.style.ParallelStyle._apply"@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*x
selfn
5torch.distributed.tensor.parallel.style.ParallelStyle"5torch.distributed.tensor.parallel.style.ParallelStyle*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh0:abstractmethod@⁄
ColwiseParallel7torch.distributed.tensor.parallel.style.ColwiseParallel"5torch.distributed.tensor.parallel.style.ParallelStyle*±
__init__@torch.distributed.tensor.parallel.style.ColwiseParallel.__init__"
None*|
selfr
7torch.distributed.tensor.parallel.style.ColwiseParallel"7torch.distributed.tensor.parallel.style.ColwiseParallel*œ
input_layoutsπ
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None *–
output_layoutsπ
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None *6
use_local_output
builtins.bool"builtins.bool *ƒ
_prepare_input_fnItorch.distributed.tensor.parallel.style.ColwiseParallel._prepare_input_fn*
input_layouts*
desired_input_layouts*
mod*

inputs*
device_mesh0:staticmethodh*ï
_partition_linear_fnLtorch.distributed.tensor.parallel.style.ColwiseParallel._partition_linear_fn*
self*
name*

module*
device_mesh*õ
_partition_embedding_fnOtorch.distributed.tensor.parallel.style.ColwiseParallel._partition_embedding_fn*
self*
name*

module*
device_mesh*√
_prepare_output_fnJtorch.distributed.tensor.parallel.style.ColwiseParallel._prepare_output_fn*
output_layouts*
use_local_output*
mod*
outputs*
device_mesh0:staticmethodh*Ω
_apply>torch.distributed.tensor.parallel.style.ColwiseParallel._apply"@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*|
selfr
7torch.distributed.tensor.parallel.style.ColwiseParallel"7torch.distributed.tensor.parallel.style.ColwiseParallel*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshrÉ
input_layoutsEtorch.distributed.tensor.parallel.style.ColwiseParallel.input_layouts™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.PlacementrÖ
output_layoutsFtorch.distributed.tensor.parallel.style.ColwiseParallel.output_layouts™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placementrì
desired_input_layoutsMtorch.distributed.tensor.parallel.style.ColwiseParallel.desired_input_layouts™
:Tuple[torch.distributed._tensor.placement_types.Replicate]j
3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Replicater|
use_local_outputHtorch.distributed.tensor.parallel.style.ColwiseParallel.use_local_output
builtins.bool"builtins.boolÒ
RowwiseParallel7torch.distributed.tensor.parallel.style.RowwiseParallel"5torch.distributed.tensor.parallel.style.ParallelStyle*±
__init__@torch.distributed.tensor.parallel.style.RowwiseParallel.__init__"
None*|
selfr
7torch.distributed.tensor.parallel.style.RowwiseParallel"7torch.distributed.tensor.parallel.style.RowwiseParallel*œ
input_layoutsπ
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None *–
output_layoutsπ
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None *6
use_local_output
builtins.bool"builtins.bool *ƒ
_prepare_input_fnItorch.distributed.tensor.parallel.style.RowwiseParallel._prepare_input_fn*
input_layouts*
desired_input_layouts*
mod*

inputs*
device_mesh0:staticmethodh*ï
_partition_linear_fnLtorch.distributed.tensor.parallel.style.RowwiseParallel._partition_linear_fn*
self*
name*

module*
device_mesh*õ
_partition_embedding_fnOtorch.distributed.tensor.parallel.style.RowwiseParallel._partition_embedding_fn*
self*
name*

module*
device_mesh*√
_prepare_output_fnJtorch.distributed.tensor.parallel.style.RowwiseParallel._prepare_output_fn*
output_layouts*
use_local_output*
mod*
outputs*
device_mesh0:staticmethodh*Ω
_apply>torch.distributed.tensor.parallel.style.RowwiseParallel._apply"@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*|
selfr
7torch.distributed.tensor.parallel.style.RowwiseParallel"7torch.distributed.tensor.parallel.style.RowwiseParallel*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshrÉ
input_layoutsEtorch.distributed.tensor.parallel.style.RowwiseParallel.input_layouts™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.PlacementrÖ
output_layoutsFtorch.distributed.tensor.parallel.style.RowwiseParallel.output_layouts™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placementr|
use_local_outputHtorch.distributed.tensor.parallel.style.RowwiseParallel.use_local_output
builtins.bool"builtins.boolr™
desired_input_layoutsMtorch.distributed.tensor.parallel.style.RowwiseParallel.desired_input_layouts¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple´
SequenceParallel8torch.distributed.tensor.parallel.style.SequenceParallel"5torch.distributed.tensor.parallel.style.ParallelStyle*¡
__init__Atorch.distributed.tensor.parallel.style.SequenceParallel.__init__"
None*~
selft
8torch.distributed.tensor.parallel.style.SequenceParallel"8torch.distributed.tensor.parallel.style.SequenceParallel*0
sequence_dim
builtins.int"builtins.int *6
use_local_output
builtins.bool"builtins.bool *À
_replicate_module_fnMtorch.distributed.tensor.parallel.style.SequenceParallel._replicate_module_fn"
Any*~
selft
8torch.distributed.tensor.parallel.style.SequenceParallel"8torch.distributed.tensor.parallel.style.SequenceParallel*&
name
builtins.str"builtins.str*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*©
_prepare_input_fnJtorch.distributed.tensor.parallel.style.SequenceParallel._prepare_input_fn*
sequence_dim*
mod*

inputs*
device_mesh0:staticmethodh*∞
_prepare_output_fnKtorch.distributed.tensor.parallel.style.SequenceParallel._prepare_output_fn*
use_local_output*
mod*
outputs*
device_mesh0:staticmethodh*¿
_apply?torch.distributed.tensor.parallel.style.SequenceParallel._apply"@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*~
selft
8torch.distributed.tensor.parallel.style.SequenceParallel"8torch.distributed.tensor.parallel.style.SequenceParallel*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshrs
sequence_dimEtorch.distributed.tensor.parallel.style.SequenceParallel.sequence_dim
builtins.int"builtins.intr}
use_local_outputItorch.distributed.tensor.parallel.style.SequenceParallel.use_local_output
builtins.bool"builtins.bool∏,
PrepareModuleInput:torch.distributed.tensor.parallel.style.PrepareModuleInput"5torch.distributed.tensor.parallel.style.ParallelStyle*÷
__init__Ctorch.distributed.tensor.parallel.style.PrepareModuleInput.__init__"
None*Ç
selfx
:torch.distributed.tensor.parallel.style.PrepareModuleInput":torch.distributed.tensor.parallel.style.PrepareModuleInput*†
input_layoutsä
ÜUnion[torch.distributed._tensor.placement_types.Placement,Tuple[Union[torch.distributed._tensor.placement_types.Placement,None]],None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.PlacementÜ
FTuple[Union[torch.distributed._tensor.placement_types.Placement,None]]π
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None
None *®
desired_input_layoutsä
ÜUnion[torch.distributed._tensor.placement_types.Placement,Tuple[Union[torch.distributed._tensor.placement_types.Placement,None]],None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.PlacementÜ
FTuple[Union[torch.distributed._tensor.placement_types.Placement,None]]π
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None
None *Ú
input_kwarg_layouts÷
[Union[builtins.dict[builtins.str,torch.distributed._tensor.placement_types.Placement],None]Í
Obuiltins.dict[builtins.str,torch.distributed._tensor.placement_types.Placement]
builtins.str"builtins.strj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.dict
None *˙
desired_input_kwarg_layouts÷
[Union[builtins.dict[builtins.str,torch.distributed._tensor.placement_types.Placement],None]Í
Obuiltins.dict[builtins.str,torch.distributed._tensor.placement_types.Placement]
builtins.str"builtins.strj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.dict
None *6
use_local_output
builtins.bool"builtins.bool *Ö
_prepare_input_argMtorch.distributed.tensor.parallel.style.PrepareModuleInput._prepare_input_arg"
Any*Ç
selfx
:torch.distributed.tensor.parallel.style.PrepareModuleInput":torch.distributed.tensor.parallel.style.PrepareModuleInput*
input
Any*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*Ã
input_layoutπ
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None*Œ
desired_layoutπ
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None*à
_prepare_input_fnLtorch.distributed.tensor.parallel.style.PrepareModuleInput._prepare_input_fn*
self*

inputs*
device_mesh*¶
_prepare_input_kwarg_fnRtorch.distributed.tensor.parallel.style.PrepareModuleInput._prepare_input_kwarg_fn*
self*

inputs*
kwarg_inputs*
device_mesh*«
_applyAtorch.distributed.tensor.parallel.style.PrepareModuleInput._apply"@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*Ç
selfx
:torch.distributed.tensor.parallel.style.PrepareModuleInput":torch.distributed.tensor.parallel.style.PrepareModuleInput*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshr≈
input_layoutsHtorch.distributed.tensor.parallel.style.PrepareModuleInput.input_layoutsÈ
RUnion[Tuple[Union[torch.distributed._tensor.placement_types.Placement,None]],None]Ü
FTuple[Union[torch.distributed._tensor.placement_types.Placement,None]]π
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None
Noner’
desired_input_layoutsPtorch.distributed.tensor.parallel.style.PrepareModuleInput.desired_input_layoutsÈ
RUnion[Tuple[Union[torch.distributed._tensor.placement_types.Placement,None]],None]Ü
FTuple[Union[torch.distributed._tensor.placement_types.Placement,None]]π
?Union[torch.distributed._tensor.placement_types.Placement,None]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement
None
Noner
use_local_outputKtorch.distributed.tensor.parallel.style.PrepareModuleInput.use_local_output
builtins.bool"builtins.boolru
with_kwargsFtorch.distributed.tensor.parallel.style.PrepareModuleInput.with_kwargs
builtins.bool"builtins.boolr“
input_kwarg_layoutsNtorch.distributed.tensor.parallel.style.PrepareModuleInput.input_kwarg_layoutsÍ
Obuiltins.dict[builtins.str,torch.distributed._tensor.placement_types.Placement]
builtins.str"builtins.strj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.dictr‚
desired_input_kwarg_layoutsVtorch.distributed.tensor.parallel.style.PrepareModuleInput.desired_input_kwarg_layoutsÍ
Obuiltins.dict[builtins.str,torch.distributed._tensor.placement_types.Placement]
builtins.str"builtins.strj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.dictÇ
PrepareModuleOutput;torch.distributed.tensor.parallel.style.PrepareModuleOutput"5torch.distributed.tensor.parallel.style.ParallelStyle*ı
__init__Dtorch.distributed.tensor.parallel.style.PrepareModuleOutput.__init__"
None*Ñ
selfz
;torch.distributed.tensor.parallel.style.PrepareModuleOutput";torch.distributed.tensor.parallel.style.PrepareModuleOutput*ß
output_layoutsí
uUnion[torch.distributed._tensor.placement_types.Placement,Tuple[torch.distributed._tensor.placement_types.Placement]]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement*Ø
desired_output_layoutsí
uUnion[torch.distributed._tensor.placement_types.Placement,Tuple[torch.distributed._tensor.placement_types.Placement]]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement*6
use_local_output
builtins.bool"builtins.bool *Ü
_prepare_out_fnKtorch.distributed.tensor.parallel.style.PrepareModuleOutput._prepare_out_fn*
self*
outputs*
device_mesh* 
_applyBtorch.distributed.tensor.parallel.style.PrepareModuleOutput._apply"@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*Ñ
selfz
;torch.distributed.tensor.parallel.style.PrepareModuleOutput";torch.distributed.tensor.parallel.style.PrepareModuleOutput*L
module@
torch.nn.modules.module.Module"torch.nn.modules.module.Module*e
device_meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshrâ
output_layoutsJtorch.distributed.tensor.parallel.style.PrepareModuleOutput.output_layouts™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placementrô
desired_output_layoutsRtorch.distributed.tensor.parallel.style.PrepareModuleOutput.desired_output_layouts™
:Tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.PlacementrÄ
use_local_outputLtorch.distributed.tensor.parallel.style.PrepareModuleOutput.use_local_output
builtins.bool"builtins.bool*£
__annotations__7torch.distributed.tensor.parallel.style.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
nntorch.nn *Ü
__all__/torch.distributed.tensor.parallel.style.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list