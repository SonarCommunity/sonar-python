
&torch.distributed.optim.functional_sgd´
_FunctionalSGD5torch.distributed.optim.functional_sgd._FunctionalSGD"builtins.object*€
__init__>torch.distributed.optim.functional_sgd._FunctionalSGD.__init__"
None*x
selfn
5torch.distributed.optim.functional_sgd._FunctionalSGD"5torch.distributed.optim.functional_sgd._FunctionalSGD*n
paramsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list**
lr 
builtins.float"builtins.float *0
momentum 
builtins.float"builtins.float *1
	dampening 
builtins.float"builtins.float *4
weight_decay 
builtins.float"builtins.float *.
nesterov
builtins.bool"builtins.bool *.
maximize
builtins.bool"builtins.bool *-
foreach
builtins.bool"builtins.bool *+
fused
builtins.bool"builtins.bool *=
_allow_empty_param_list
builtins.bool"builtins.bool *ò

step_param@torch.distributed.optim.functional_sgd._FunctionalSGD.step_param"
Any*x
selfn
5torch.distributed.optim.functional_sgd._FunctionalSGD"5torch.distributed.optim.functional_sgd._FunctionalSGD*7
param,
torch._tensor.Tensor"torch._tensor.Tensor*f
grad\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*ö
step:torch.distributed.optim.functional_sgd._FunctionalSGD.step"
Any*x
selfn
5torch.distributed.optim.functional_sgd._FunctionalSGD"5torch.distributed.optim.functional_sgd._FunctionalSGD*®
	gradientsž
/builtins.list[Union[torch._tensor.Tensor,None]]\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None"builtins.list8rÇ
defaults>torch.distributed.optim.functional_sgd._FunctionalSGD.defaults{
*builtins.dict[builtins.str,builtins.float]
builtins.str"builtins.str 
builtins.float"builtins.float"builtins.dictrj
nesterov>torch.distributed.optim.functional_sgd._FunctionalSGD.nesterov
builtins.bool"builtins.boolrj
maximize>torch.distributed.optim.functional_sgd._FunctionalSGD.maximize
builtins.bool"builtins.boolrh
foreach=torch.distributed.optim.functional_sgd._FunctionalSGD.foreach
builtins.bool"builtins.boolrd
fused;torch.distributed.optim.functional_sgd._FunctionalSGD.fused
builtins.bool"builtins.boolrM
state;torch.distributed.optim.functional_sgd._FunctionalSGD.state
Anyr¥
param_groupAtorch.distributed.optim.functional_sgd._FunctionalSGD.param_groupÒ
?builtins.dict[builtins.str,builtins.list[torch._tensor.Tensor]]
builtins.str"builtins.strb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.dict*¢
__annotations__6torch.distributed.optim.functional_sgd.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
Ftorch.optim._functional *…
__all__.torch.distributed.optim.functional_sgd.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list